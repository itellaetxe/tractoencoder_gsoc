{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to export the model weights from PyTorch ---> ONNX ---> TensorFlow (Didn't work well...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tractolearn.models.track_ae_cnn1d_incr_feat_strided_conv_fc_upsamp_reflect_pad_pytorch as AE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"/home/teitxe/data/tractolearn_data/\"\n",
    "state_dict = torch.load(os.path.join(weights_path, \"best_model_contrastive_tractoinferno_hcp.pt\"), map_location=torch.device('cpu'))\n",
    "net = AE_model.IncrFeatStridedConvFCUpsampReflectPadAE(32)\n",
    "dummy_input = torch.randn(1, 3, 256)\n",
    "net(dummy_input)[0][0][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the weights into the model and export them to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net.load_state_dict(state_dict[\"state_dict\"])\n",
    "onnx_file = os.path.join(weights_path, \"best_model_contrastive_tractoinferno_hcp.onnx\")\n",
    "torch.onnx.export(net, dummy_input, onnx_file, input_names=[\"input\"], output_names=[\"output\"], \n",
    "                  export_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "if not os.path.exists('/home/teitxe/data/tractolearn_data/tf_model'):\n",
    "    container = 'docker run --rm -v /home/teitxe:/workdir -w /workdir docker.io/pinto0309/onnx2tf:1.22.3 /bin/bash -c \"'\n",
    "    tf_model_path = '/workdir/data/tractolearn_data/tf_model'\n",
    "    onnx_model_path = '/workdir/data/tractolearn_data/best_model_contrastive_tractoinferno_hcp.onnx'\n",
    "    command = f'mkdir -p {tf_model_path} && onnx2tf -i {onnx_model_path} -o {tf_model_path}\"'\n",
    "    print(container + command)\n",
    "    sp.run(container + command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to load the model into TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_tf_model_path = '/home/teitxe/data/tractolearn_data/tf_model'\n",
    "model = tf.saved_model.load(local_tf_model_path)\n",
    "\n",
    "\n",
    "print((model(input_streamline))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for streamline in streamlines:\n",
    "    outputs.append(model(streamline.reshape(1, 256, 3))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the header of MNI152\n",
    "mni152 = nib.load(\"/home/teitxe/data/tractolearn_data/mni_masked.nii.gz\")\n",
    "tractogram = nib.streamlines.Tractogram(outputs, affine_to_rasmm=mni152.affine)\n",
    "nib.streamlines.save(tractogram, \"test.trk\", header=mni152.header)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
